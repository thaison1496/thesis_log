Loading data...
Building model...
Model summary...
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
word_index (InputLayer)         (None, 85)           0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 85, 300)      131901600   word_index[0][0]                 
__________________________________________________________________________________________________
masking_1 (Masking)             (None, 85, 300)      0           embedding_1[0][0]                
__________________________________________________________________________________________________
additional_feature (InputLayer) (None, 85, 23)       0                                            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 85, 323)      0           masking_1[0][0]                  
                                                                 additional_feature[0][0]         
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 85, 128)      198656      concatenate_1[0][0]              
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 85, 128)      98816       bidirectional_1[0][0]            
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, 85, 8)        1032        bidirectional_2[0][0]            
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 85, 8)        0           time_distributed_1[0][0]         
==================================================================================================
Total params: 132,200,104
Trainable params: 298,504
Non-trainable params: 131,901,600
__________________________________________________________________________________________________
None
Training model...
Train on 2000 samples, validate on 2000 samples
Epoch 1/1

  50/2000 [..............................] - ETA: 1:06 - loss: 2.0894 - acc: 0.0851
 100/2000 [>.............................] - ETA: 39s - loss: 2.0434 - acc: 0.2139 
 150/2000 [=>............................] - ETA: 30s - loss: 1.9777 - acc: 0.4185
 200/2000 [==>...........................] - ETA: 25s - loss: 1.9162 - acc: 0.5544
 250/2000 [==>...........................] - ETA: 22s - loss: 1.8547 - acc: 0.6412
 300/2000 [===>..........................] - ETA: 20s - loss: 1.7891 - acc: 0.6992
 350/2000 [====>.........................] - ETA: 18s - loss: 1.7160 - acc: 0.7390
 400/2000 [=====>........................] - ETA: 17s - loss: 1.6288 - acc: 0.7701
 450/2000 [=====>........................] - ETA: 16s - loss: 1.5421 - acc: 0.7941
 500/2000 [======>.......................] - ETA: 15s - loss: 1.4500 - acc: 0.8141
 550/2000 [=======>......................] - ETA: 14s - loss: 1.3584 - acc: 0.8286
 600/2000 [========>.....................] - ETA: 13s - loss: 1.2706 - acc: 0.8417
 650/2000 [========>.....................] - ETA: 13s - loss: 1.1878 - acc: 0.8530
 700/2000 [=========>....................] - ETA: 12s - loss: 1.1144 - acc: 0.8629
 750/2000 [==========>...................] - ETA: 11s - loss: 1.0465 - acc: 0.8715
 800/2000 [===========>..................] - ETA: 11s - loss: 0.9867 - acc: 0.8790
 850/2000 [===========>..................] - ETA: 10s - loss: 0.9322 - acc: 0.8858
 900/2000 [============>.................] - ETA: 10s - loss: 0.8875 - acc: 0.8913
 950/2000 [=============>................] - ETA: 9s - loss: 0.8451 - acc: 0.8966 
1000/2000 [==============>...............] - ETA: 9s - loss: 0.8067 - acc: 0.9012
1050/2000 [==============>...............] - ETA: 8s - loss: 0.7758 - acc: 0.9049
1100/2000 [===============>..............] - ETA: 8s - loss: 0.7482 - acc: 0.9084
1150/2000 [================>.............] - ETA: 7s - loss: 0.7285 - acc: 0.9110
1200/2000 [=================>............] - ETA: 7s - loss: 0.6991 - acc: 0.9146
1250/2000 [=================>............] - ETA: 6s - loss: 0.6732 - acc: 0.9178
1300/2000 [==================>...........] - ETA: 6s - loss: 0.6493 - acc: 0.9208
1350/2000 [===================>..........] - ETA: 5s - loss: 0.6295 - acc: 0.9233
1400/2000 [====================>.........] - ETA: 5s - loss: 0.6099 - acc: 0.9257
1450/2000 [====================>.........] - ETA: 4s - loss: 0.5913 - acc: 0.9281
1500/2000 [=====================>........] - ETA: 4s - loss: 0.5755 - acc: 0.9300
1550/2000 [======================>.......] - ETA: 3s - loss: 0.5638 - acc: 0.9316
1600/2000 [=======================>......] - ETA: 3s - loss: 0.5535 - acc: 0.9329
1650/2000 [=======================>......] - ETA: 3s - loss: 0.5388 - acc: 0.9347
1700/2000 [========================>.....] - ETA: 2s - loss: 0.5250 - acc: 0.9363
1750/2000 [=========================>....] - ETA: 2s - loss: 0.5136 - acc: 0.9377
1800/2000 [==========================>...] - ETA: 1s - loss: 0.5015 - acc: 0.9392
1850/2000 [==========================>...] - ETA: 1s - loss: 0.4887 - acc: 0.9408
1900/2000 [===========================>..] - ETA: 0s - loss: 0.4780 - acc: 0.9420
1950/2000 [============================>.] - ETA: 0s - loss: 0.4681 - acc: 0.9432
2000/2000 [==============================] - 21s 11ms/step - loss: 0.4593 - acc: 0.9443 - val_loss: 0.1092 - val_acc: 0.9867
processed 13328 tokens with 0 phrases; found: 182 phrases; correct: 0.
accuracy:  98.09%; precision:   0.00%; recall:   0.00%; FB1:   0.00
              LOC: precision:   0.00%; recall:   0.00%; FB1:   0.00  71
              ORG: precision:   0.00%; recall:   0.00%; FB1:   0.00  25
              PER: precision:   0.00%; recall:   0.00%; FB1:   0.00  86
Testing model...
['O', 'B-ORG', 'I-ORG', 'B-LOC', 'B-PER', 'I-PER', 'I-LOC']
(667, 85)
Running time: 
0:00:40.184555
Loading data...
Building model...
Model summary...
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
word_index (InputLayer)         (None, 103)          0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 103, 300)     131901600   word_index[0][0]                 
__________________________________________________________________________________________________
masking_2 (Masking)             (None, 103, 300)     0           embedding_2[0][0]                
__________________________________________________________________________________________________
additional_feature (InputLayer) (None, 103, 25)      0                                            
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 103, 325)     0           masking_2[0][0]                  
                                                                 additional_feature[0][0]         
__________________________________________________________________________________________________
bidirectional_3 (Bidirectional) (None, 103, 128)     199680      concatenate_2[0][0]              
__________________________________________________________________________________________________
bidirectional_4 (Bidirectional) (None, 103, 128)     98816       bidirectional_3[0][0]            
__________________________________________________________________________________________________
time_distributed_2 (TimeDistrib (None, 103, 8)       1032        bidirectional_4[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 103, 8)       0           time_distributed_2[0][0]         
==================================================================================================
Total params: 132,201,128
Trainable params: 299,528
Non-trainable params: 131,901,600
__________________________________________________________________________________________________
None
Training model...
Train on 1664 samples, validate on 1664 samples
Epoch 1/1

  50/1664 [..............................] - ETA: 1:08 - loss: 2.0988 - acc: 0.0768
 100/1664 [>.............................] - ETA: 40s - loss: 2.0518 - acc: 0.2117 
 150/1664 [=>............................] - ETA: 31s - loss: 2.0118 - acc: 0.3443
 200/1664 [==>...........................] - ETA: 26s - loss: 1.9605 - acc: 0.4815
 250/1664 [===>..........................] - ETA: 23s - loss: 1.9067 - acc: 0.5733
 300/1664 [====>.........................] - ETA: 20s - loss: 1.8522 - acc: 0.6369
 350/1664 [=====>........................] - ETA: 19s - loss: 1.7925 - acc: 0.6764
 400/1664 [======>.......................] - ETA: 17s - loss: 1.7233 - acc: 0.7082
 450/1664 [=======>......................] - ETA: 16s - loss: 1.6386 - acc: 0.7360
 500/1664 [========>.....................] - ETA: 15s - loss: 1.5612 - acc: 0.7581
 550/1664 [========>.....................] - ETA: 14s - loss: 1.4753 - acc: 0.7750
 600/1664 [=========>....................] - ETA: 13s - loss: 1.3906 - acc: 0.7897
 650/1664 [==========>...................] - ETA: 12s - loss: 1.3081 - acc: 0.8038
 700/1664 [===========>..................] - ETA: 11s - loss: 1.2337 - acc: 0.8153
 750/1664 [============>.................] - ETA: 11s - loss: 1.1865 - acc: 0.8221
 800/1664 [=============>................] - ETA: 10s - loss: 1.1297 - acc: 0.8306
 850/1664 [==============>...............] - ETA: 9s - loss: 1.0875 - acc: 0.8370 
 900/1664 [===============>..............] - ETA: 8s - loss: 1.0445 - acc: 0.8435
 950/1664 [================>.............] - ETA: 8s - loss: 1.0155 - acc: 0.8480
1000/1664 [=================>............] - ETA: 7s - loss: 0.9793 - acc: 0.8536
1050/1664 [=================>............] - ETA: 6s - loss: 0.9498 - acc: 0.8583
1100/1664 [==================>...........] - ETA: 6s - loss: 0.9218 - acc: 0.8627
1150/1664 [===================>..........] - ETA: 5s - loss: 0.9011 - acc: 0.8661
1200/1664 [====================>.........] - ETA: 5s - loss: 0.8854 - acc: 0.8686
1250/1664 [=====================>........] - ETA: 4s - loss: 0.8718 - acc: 0.8709
1300/1664 [======================>.......] - ETA: 4s - loss: 0.8537 - acc: 0.8736
1350/1664 [=======================>......] - ETA: 3s - loss: 0.8337 - acc: 0.8766
1400/1664 [========================>.....] - ETA: 2s - loss: 0.8251 - acc: 0.8777
1450/1664 [=========================>....] - ETA: 2s - loss: 0.8099 - acc: 0.8799
1500/1664 [==========================>...] - ETA: 1s - loss: 0.7910 - acc: 0.8826
1550/1664 [==========================>...] - ETA: 1s - loss: 0.7785 - acc: 0.8844
1600/1664 [===========================>..] - ETA: 0s - loss: 0.7696 - acc: 0.8854
1650/1664 [============================>.] - ETA: 0s - loss: 0.7543 - acc: 0.8875
1664/1664 [==============================] - 23s 14ms/step - loss: 0.7512 - acc: 0.8879 - val_loss: 0.3211 - val_acc: 0.9442
processed 12725 tokens with 0 phrases; found: 499 phrases; correct: 0.
accuracy:  92.86%; precision:   0.00%; recall:   0.00%; FB1:   0.00
              LOC: precision:   0.00%; recall:   0.00%; FB1:   0.00  110
              ORG: precision:   0.00%; recall:   0.00%; FB1:   0.00  151
              PER: precision:   0.00%; recall:   0.00%; FB1:   0.00  238
Testing model...
['O', 'B-LOC', 'B-ORG', 'I-ORG', 'I-LOC', 'B-PER', 'I-PER']
(554, 103)
Running time: 
0:00:46.518979
Loading data...
Building model...
